{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81c872d",
   "metadata": {},
   "source": [
    "# Extracting data from the data engineering networking WhatsApp group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "635efcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d3f59",
   "metadata": {},
   "source": [
    "# Taking a txt file and transforming it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b86c4ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dia   Hora Remetente\n",
      "0     12  10:09   SISTEMA\n",
      "1     10  19:08   SISTEMA\n",
      "2     10  19:08   SISTEMA\n",
      "3     10  19:08   SISTEMA\n",
      "4     12  10:09   SISTEMA\n",
      "...   ..    ...       ...\n",
      "1216  14  16:42   SISTEMA\n",
      "1217  14  17:45   SISTEMA\n",
      "1218  14  19:05   SISTEMA\n",
      "1219  14  19:31   SISTEMA\n",
      "1220  14  20:06   SISTEMA\n",
      "\n",
      "[1221 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/engenharia de dados/files/whats/networking.txt\"\n",
    "\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "default = re.compile(\n",
    "    r\"^(?P<day>\\d{1,2})/\\d{1,2}/\\d{4} \"\n",
    "    r\"(?P<hour>\\d{2}:\\d{2}) - \"\n",
    "    r\"(?:(?P<sender>.*?): )?\"\n",
    "    r\"(?P<message>.*)$\"\n",
    ")\n",
    "\n",
    "data = []\n",
    "current_message = None\n",
    "\n",
    "for line in content:\n",
    "    match = default.match(line)\n",
    "    if match:\n",
    "        day = match.group(\"day\")\n",
    "        hour = match.group(\"hour\")\n",
    "        sender = match.group(\"sender\") or \"SISTEMA\"\n",
    "        message = match.group(\"message\")\n",
    "        \n",
    "        current_message = [day, hour, sender if sender else \"SISTEMA\", message]\n",
    "        data.append(current_message)\n",
    "    else:\n",
    "        if current_message:\n",
    "            current_message[3] += \"\\n\" + line \n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Dia\", \"Hora\", \"Remetente\", \"Mensagem\"])\n",
    "\n",
    "print(df[[\"Dia\", \"Hora\", \"Remetente\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2e465",
   "metadata": {},
   "source": [
    "# Filtering only messages that contain LinkedIn and transforming the data only into LinkedIn links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3cb4910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Hora                                           Linkedin\n",
      "168   12:00        https://www.linkedin.com/in/iasmim-horrana/\n",
      "169   12:00            https://www.linkedin.com/in/max-mitsuya\n",
      "170   12:00  https://www.linkedin.com/in/jo%C3%A3o-victor-1...\n",
      "176   12:00  https://www.linkedin.com/in/maria-eduarda-nasc...\n",
      "178   12:01  https://www.linkedin.com/in/ygor-amaro-114613231/\n",
      "...     ...                                                ...\n",
      "1197  13:59  https://www.linkedin.com/in/allanfmachado?utm_...\n",
      "1198  13:59         https://www.linkedin.com/in/lucaswenceslau\n",
      "1199  13:59  https://www.linkedin.com/in/riulersilverio?utm...\n",
      "1200  14:00            https://www.linkedin.com/in/luanbocalon\n",
      "1201  14:00            https://www.linkedin.com/in/ronneyagra/\n",
      "\n",
      "[535 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_linkedin = df[df[\"Mensagem\"].str.contains(r\"linkedin\\.com\", case=False, na=False)].copy()\n",
    "\n",
    "df_linkedin[\"Mensagem\"] = df_linkedin[\"Mensagem\"].str.extract(\n",
    "    r\"((?:https?://)?(?:www\\.)?linkedin\\.com[^\\s]+)\",\n",
    "    expand=False,\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "df_linkedin[\"Mensagem\"] = df_linkedin[\"Mensagem\"].apply(\n",
    "    lambda x: \"https://\" + x if pd.notnull(x) and not x.startswith(\"http\") else x\n",
    ")\n",
    "\n",
    "df_linkedin.rename(columns={\"Mensagem\": \"Linkedin\"}, inplace=True)\n",
    "\n",
    "print(df_linkedin[[\"Hora\", \"Linkedin\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369992b8",
   "metadata": {},
   "source": [
    "## Removing duplicate data, as they may have sent LinkedIn again on other days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0568779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779     https://www.linkedin.com/in/miguel-gon%C3%A7al...\n",
       "1066              https://www.linkedin.com/in/oceanalves/\n",
       "1154    https://www.linkedin.com/in/maria-eduarda-nasc...\n",
       "Name: Linkedin, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated = df_linkedin[df_linkedin.duplicated()]\n",
    "duplicated[\"Linkedin\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f190eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkedin = df_linkedin.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6309ab0",
   "metadata": {},
   "source": [
    "# Generating the Excel file, adjusting the column widths, and turning the LinkedIn column into a hyperlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab770003",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_excel = r\"D:\\\\engenharia de dados\\\\files\\\\whats\\\\networking.xlsx\"\n",
    "\n",
    "df_linkedin.to_excel(path_excel, index=False)\n",
    "\n",
    "wb = load_workbook(path_excel)\n",
    "ws = wb.active\n",
    "\n",
    "# Turns Column D of the created Excel file into a hyperlink\n",
    "for row in range(2, ws.max_row + 1):\n",
    "    cell = ws[f\"D{row}\"]\n",
    "    url = cell.value\n",
    "    if url:\n",
    "        cell.hyperlink = url\n",
    "        cell.value = \"Linkedin\"\n",
    "        cell.style = \"Hyperlink\"\n",
    "\n",
    "# Adjust the size of the cells to make it visually appealing\n",
    "for col_cells in ws.columns:\n",
    "    max_len = 0\n",
    "    col_letter = get_column_letter(col_cells[0].column)\n",
    "    for c in col_cells:\n",
    "        if c.value is not None:\n",
    "            max_len = max(max_len, len(str(c.value)))\n",
    "    ws.column_dimensions[col_letter].width = max(10, max_len + 2)\n",
    "\n",
    "wb.save(path_excel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgbds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
